---
content_type: resource
draft: false
file: null
file_size: 37914992
file_type: ''
image_metadata:
  caption: ''
  credit: ''
  image-alt: ''
learning_resource_types:
- Podcasts
license: https://creativecommons.org/licenses/by-nc-sa/4.0/
resourcetype: Video
title: "The Human Element in Machine Learning with Catherine D\u2019Ignazio, Jacob\
  \ Andreas & Harini Suresh"
uid: a99d1be5-89aa-4837-9fb9-99393eac970a
video_files:
  archive_url: https://archive.org/download/chalk-radio/S03E05_Dignazio_Andreas_Suresh_360p.mp4
  video_captions_file: /courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/MbzbbvTlL1Y_captions.webvtt
  video_thumbnail_file: https://img.youtube.com/vi/MbzbbvTlL1Y/default.jpg
  video_transcript_file: /courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/MbzbbvTlL1Y_transcript.pdf
video_metadata:
  source: youtube
  video_speakers: ''
  video_tags: ''
  youtube_description: ''
  youtube_id: MbzbbvTlL1Y
---
When computer science was in its infancy, programmers quickly realized that though computers are astonishingly powerful tools, the results they achieve are only as good as the data you feed into them. (This principle was quickly formalized as GIGO: “Garbage In, Garbage Out.”) What was true in the era of the UNIVAC has proved still to be true in the era of machine learning: among other well-publicized AI fiascos, chatbots that have interacted with bigots have learned to spew racist invective, while facial-recognition software trained solely on images of white people sometimes fails to recognize people of color as human. In this episode, we meet Prof. Catherine D’Ignazio of MIT’s Department of Urban Studies and Planning (DUSP) and Prof. Jacob Andreas and Harini Suresh of the Department of Electrical Engineering and Computer Science. In 2021, D’Ignazio, Andreas, and Suresh collaborated as part of the Social and Ethical Responsibilities of Computing initiative from the Schwartzman College of Computing in a project to teach computer science students in 6.864 Natural Language Processing to recognize how deep learning systems can replicate and magnify the biases inherent in the data sets that are used to train them.